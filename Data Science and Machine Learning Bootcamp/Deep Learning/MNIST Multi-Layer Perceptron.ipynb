{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7face237f4e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7face23ed5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: Dict of bias values\n",
    "    '''\n",
    "    \n",
    "    # First Hidden Layer with RELU Activation\n",
    "    # X * Weight + Bias_Value\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    \n",
    "    # RELU(X * W + B) = RELU -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_33:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_34:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_35:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float',[None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist.train.next_batch(10) returns tuples representation of 10 samples of shape(784, ) and their classes represented in a list. \n",
    "\n",
    "For example:-\n",
    "\n",
    "Xsamp, ysamp = t\n",
    "\n",
    "Xsamp represents shape of each sample, 784 (28 * 28), and ysamp represents list of classes as 0 and 1 that corresponds to the number in image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost158.6370\n",
      "Epoch: 2 cost40.9708\n",
      "Epoch: 3 cost25.6342\n",
      "Epoch: 4 cost17.6895\n",
      "Epoch: 5 cost12.7466\n",
      "Epoch: 6 cost9.3406\n",
      "Epoch: 7 cost7.0139\n",
      "Epoch: 8 cost5.0554\n",
      "Epoch: 9 cost3.8363\n",
      "Epoch: 10 cost2.8142\n",
      "Epoch: 11 cost2.1038\n",
      "Epoch: 12 cost1.4788\n",
      "Epoch: 13 cost1.2569\n",
      "Epoch: 14 cost0.9195\n",
      "Epoch: 15 cost0.7212\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)  #55000/100\n",
    "    \n",
    "    for i in range(total_batch):  # Iterates for 550 times\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)  # Every next_batch will have size of 100\n",
    "        \n",
    "        _,c = sess.run([optimizer,cost], feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost{:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print (\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.cast(correct_prediction, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94840002"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images, y:mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
